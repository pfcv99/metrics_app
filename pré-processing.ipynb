{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MANE parsing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.biostars.org/p/93011/\n",
    "\n",
    "10.1 years ago\n",
    "pristanna ▴ 750\n",
    "Download a bed file for the canonical transcripts using UCSC Table Browser:\n",
    "\n",
    "track: UCSC Genes\n",
    "table: knownCanonical\n",
    "output format: select fields from primary and related tables\n",
    "press get output\n",
    "select fields from hg19.knownCanonical: chrom, chromStart, chromEnd,\n",
    "transcript select fields from hg19.kgXref: geneSymbol\n",
    "press get output\n",
    "The file UCSC_canonical.bed looks like:\n",
    "\n",
    "#hg19.knownCanonical.chrom      hg19.knownCanonical.chromStart  hg19.knownCanonical.chromEnd    hg19.knownCanonical.transcript  hg19.kgXref.geneSymbol\n",
    "chr1    11873   14409   uc010nxq.1      DDX11L1\n",
    "chr1    14361   19759   uc009viu.3      WASH7P\n",
    "chr1    14406   29370   uc009viw.2      WASH7P\n",
    "chr1    34610   36081   uc001aak.3      FAM138F\n",
    "chr1    69090   70008   uc001aal.1      OR4F5\n",
    "chr1    134772  140566  uc021oeg.2      LOC729737\n",
    "chr1    321083  321115  uc001aaq.2      DQ597235\n",
    "chr1    321145  321207  uc001aar.2      DQ599768\n",
    "chr1    322036  326938  uc009vjk.2      LOC100133331\n",
    "Download a bed file for all UCSC exons using UCSC Table Browser:\n",
    "\n",
    "track: UCSC Genes\n",
    "table: knownGene\n",
    "output format: BED - browser extensible data\n",
    "press get output\n",
    "select option Exons\n",
    "press get BED\n",
    "The file UCSC_exons.bed looks like that:\n",
    "\n",
    "chr1    11873   12227   uc001aaa.3_exon_0_0_chr1_11874_f        0       +\n",
    "chr1    12612   12721   uc001aaa.3_exon_1_0_chr1_12613_f        0       +\n",
    "chr1    13220   14409   uc001aaa.3_exon_2_0_chr1_13221_f        0       +\n",
    "chr1    11873   12227   uc010nxr.1_exon_0_0_chr1_11874_f        0       +\n",
    "chr1    12645   12697   uc010nxr.1_exon_1_0_chr1_12646_f        0       +\n",
    "chr1    13220   14409   uc010nxr.1_exon_2_0_chr1_13221_f        0       +\n",
    "chr1    11873   12227   uc010nxq.1_exon_0_0_chr1_11874_f        0       +\n",
    "chr1    12594   12721   uc010nxq.1_exon_1_0_chr1_12595_f        0       +\n",
    "chr1    13402   14409   uc010nxq.1_exon_2_0_chr1_13403_f        0       +\n",
    "chr1    14361   14829   uc009vis.3_exon_0_0_chr1_14362_r        0       -\n",
    "Modify the file to separate the transcript name of the rest of information:\n",
    "\n",
    "awk '{split ($4,a,\"_\"); {print $1\"\\t\"$2\"\\t\"$3\"\\t\"a[1]\"\\t\"a[3]\"\\t\"$6}}' UCSC_exons.bed > UCSC_exons_modif.bed\n",
    "The file UCSC_exons_modif.bed:\n",
    "\n",
    "chr1    11873   12227   uc001aaa.3      0       +\n",
    "chr1    12612   12721   uc001aaa.3      1       +\n",
    "chr1    13220   14409   uc001aaa.3      2       +\n",
    "chr1    11873   12227   uc010nxr.1      0       +\n",
    "chr1    12645   12697   uc010nxr.1      1       +\n",
    "chr1    13220   14409   uc010nxr.1      2       +\n",
    "chr1    11873   12227   uc010nxq.1      0       +\n",
    "chr1    12594   12721   uc010nxq.1      1       +\n",
    "chr1    13402   14409   uc010nxq.1      2       +\n",
    "chr1    14361   14829   uc009vis.3      0       -\n",
    "Join the sorted files based on the transcript identificator:\n",
    "\n",
    "join -1 4 -2 4 <(sort -k4 UCSC_exons_modif.bed ) <(sort -k4 UCSC_canonical.bed) | awk '{print $2\"\\t\"$3\"\\t\"$4\"\\t\"$10\"\\t\"$5\"\\t\"$6}' | bedtools sort -i \"-\" > UCSC_exons_modif_canonical.bed\n",
    "The final file contains exons of the canonical transcripts:\n",
    "\n",
    "chr1    11873   12227   DDX11L1 0       +\n",
    "chr1    12594   12721   DDX11L1 1       +\n",
    "chr1    13402   14409   DDX11L1 2       +\n",
    "chr1    14361   14829   WASH7P  0       -\n",
    "chr1    14406   16765   WASH7P  0       -\n",
    "chr1    14969   15038   WASH7P  1       -\n",
    "chr1    15795   15947   WASH7P  2       -\n",
    "chr1    16606   16765   WASH7P  3       -\n",
    "chr1    16857   17055   WASH7P  4       -\n",
    "chr1    16857   17055   WASH7P  1       -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "awk '{split ($5,a,\"_\"); {print $1\"\\t\"$2\"\\t\"$3\"\\t\"a[1]\"\\t\"a[3]\"\\t\"$6}}' hg19_Twist_ILMN_Exome_2.0_Plus_Panel_annotated.BED > hg19_Twist_ILMN_Exome_2.0_Plus_Panel_annotated.BED_modif.bed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "join -1 4 -2 4 <(sort -k4 data/regions/genome_exons/MANE_hg38_exons_modif.bed ) <(sort -k4 data/regions/genome_exons/MANE_hg38.bed) | awk '{print $2\"\\t\"$3\"\\t\"$4\"\\t\"$10\"\\t\"$5\"\\t\"$6}' | bedtools sort -i \"-\" > data/regions/genome_exons/MANE_hg38_exons_modif_MANE.bed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('data/regions/genome_exons/MANE_exons_modif_MANE.bed', sep='\\t', header=None)\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_lst = df[3].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_lst = sorted(gene_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "awk '{if ($4 == \"PKD1\") {sub(/^chr/, \"\", $1); print}}' 'data/regions/genome_exons/UCSC_hg19_exons_modif_canonical.bed' | samtools depth -b - 'data/mapped/1111751_PKD1.bam' > 'data/1111751_PKD1.depth'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "awk '{if ($4 == \"BRCA1\" || $4 == \"BRCA2\") {sub(/^chr/, \"\", $1); print}}' 'data/regions/genome_exons/UCSC_hg19_exons_modif_canonical.bed' | samtools depth -b - 'data/mapped/1101542.bam' > 'data/1101542.depth'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "awk '{sub(/^chr/, \"\", $1); print}' 'data/regions/genome_exons/MANE_hg38_exons_modif_MANE.bed' | samtools depth -b - 'data/mapped/1101542.bam' > 'data/1101542.depth'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "awk -v gene=\"PKD1\" '{if ($4 == gene) {sub(/^chr/, \"\", $1); print}}' 'data/regions/genome_exons/UCSC_hg19_exons_modif_canonical.bed' | samtools depth -b - 'data/mapped/1111751_PKD1.bam' > 'data/1111751_PKD1.depth'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "samtools depth -a 'data/mapped/1101542.bam' > 'data/1101542.depth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "samtools depth -b data/regions/BRCA1_BRCA2_NGv.bed data/mapped/1101542.bam > data/1101542.depth #Painel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "samtools depth -b data/regions/PKD1.bed data/mapped/1110366_PKD1.bam > data/1110366_PKD1.depth #Single Gene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "samtools depth -b data/regions/NEB.bed data/mapped/1120554.bam > data/1120554.depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "samtools depth -b <bed> <bam> > <depth> #Single Gene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install --trusted-host pypi.org --trusted-host files.pythonhosted.org pycaret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame([\n",
    "      dict(Task=\"State-of-the-art review\", Start='2023-11-21', Finish='2023-11-24', Type='Survey'),\n",
    "      dict(Task=\"State-of-the-art review\", Start='2023-11-27', Finish='2023-12-01', Type='Survey'),\n",
    "      dict(Task=\"State-of-the-art review\", Start='2023-12-04', Finish='2023-12-08', Type='Survey'),\n",
    "      dict(Task=\"State-of-the-art review\", Start='2023-12-11', Finish='2023-12-15', Type='Survey'),\n",
    "      dict(Task=\"State-of-the-art review\", Start='2023-12-18', Finish='2023-12-21', Type='Survey'),\n",
    "            dict(Task=\"Internship Report\", Start='2023-12-18', Finish='2023-12-21', Type='Documentation'),\n",
    "      dict(Task=\"Getting familiar with Streamlit\", Start='2024-01-02', Finish='2024-01-05', Type='Testing'),\n",
    "            dict(Task=\"Samtools testing\", Start='2024-01-02', Finish='2024-01-05', Type='Testing'),\n",
    "      dict(Task=\"Streamlit testing\", Start='2024-01-08', Finish='2024-01-12', Type='Testing'),\n",
    "      dict(Task=\"First version in Jupyter Notebook\", Start='2024-01-15', Finish='2024-01-19', Type='Development'),\n",
    "      dict(Task=\"Estruturação dos diretórios e criação de repositório no Github\", Start='2024-01-22', Finish='2024-01-26', Type='Development'),\n",
    "            dict(Task=\"Single Gene development\", Start='2024-01-22', Finish='2024-01-26', Type='Development'),\n",
    "      dict(Task=\"Single Gene development\", Start='2024-01-29', Finish='2024-02-02', Type='Development'),\n",
    "      dict(Task=\"Single Gene testing\", Start='2024-02-05', Finish='2024-02-09', Type='Testing'),\n",
    "            dict(Task=\"Single Gene validation\", Start='2024-02-05', Finish='2024-02-09', Type='Validation'),\n",
    "      dict(Task=\"Versão estável para Single Gene\", Start='2024-02-12', Finish='2024-02-16', Type='Deployment'),\n",
    "            dict(Task=\"Criação de uma nova versão de desenvolvimento\", Start='2024-02-12', Finish='2024-02-16', Type='Development'),\n",
    "            dict(Task=\"Internship Report\", Start='2024-02-12', Finish='2024-02-16', Type='Documentation'),\n",
    "      dict(Task=\"Internship Report\", Start='2024-02-19', Finish='2024-02-23', Type='Documentation'),\n",
    "      dict(Task=\"Adicionada feature de divisão em páginas\", Start='2024-02-26', Finish='2024-03-01', Type='Development'),\n",
    "            dict(Task=\"Gene panel feature development\", Start='2024-02-26', Finish='2024-03-01', Type='Development'),\n",
    "      dict(Task=\"Gene panel feature development\", Start='2024-03-04', Finish='2024-03-08', Type='Development'),\n",
    "      dict(Task=\"Gene panel feature development\", Start='2024-03-11', Finish='2024-03-15', Type='Development'),\n",
    "      dict(Task=\"Universal BED - MANE and UCSC Canonical (development)\", Start='2024-03-18', Finish='2024-03-22', Type='Development'),\n",
    "            dict(Task=\"Universal BED - MANE and UCSC Canonical (testing)\", Start='2024-03-18', Finish='2024-03-22', Type='Testing'),\n",
    "            dict(Task=\"Universal BED - MANE and UCSC Canonical (validation)\", Start='2024-03-18', Finish='2024-03-22', Type='Validation'),\n",
    "            dict(Task=\"Gene panel creation tool\", Start='2024-03-18', Finish='2024-03-22', Type='Development'),\n",
    "      dict(Task=\"Gene panel feature development\", Start='2024-03-25', Finish='2024-03-29', Type='Development'),\n",
    "      dict(Task=\"Gene panel feature development\", Start='2024-04-01', Finish='2024-04-05', Type='Development'),\n",
    "      dict(Task=\"Gene panel feature testing\", Start='2024-04-08', Finish='2024-04-12', Type='Testing'),\n",
    "      dict(Task=\"Internship Report\", Start='2024-04-15', Finish='2024-04-19', Type='Documentation'),\n",
    "      dict(Task=\"Internship Report\", Start='2024-04-22', Finish='2024-04-26', Type='Documentation'),\n",
    "      dict(Task=\"State-of-the-art review\", Start='2024-04-29', Finish='2024-05-03', Type='Survey'),\n",
    "      dict(Task=\"Internship Report\", Start='2024-05-06', Finish='2024-05-10', Type='Development'),\n",
    "      dict(Task=\"Internship Report\", Start='2024-05-13', Finish='2024-05-17', Type='Development'),\n",
    "      dict(Task=\"Internship Report\", Start='2024-05-20', Finish='2024-05-24', Type='Development'),\n",
    "      dict(Task=\"Internship Report\", Start='2024-05-27', Finish='2024-05-31', Type='Development'),\n",
    "      dict(Task=\"Internship Report\", Start='2024-06-03', Finish='2024-06-07', Type='Documentation'),\n",
    "      dict(Task=\"Internship Report\", Start='2024-06-10', Finish='2024-06-14', Type='Documentation'),\n",
    "      dict(Task=\"Internship Report\", Start='2024-06-17', Finish='2024-06-21', Type='Documentation'),\n",
    "      dict(Task=\"Internship Report\", Start='2024-06-24', Finish='2024-06-28', Type='Documentation'),\n",
    "      dict(Task=\"Internship Report\", Start='2024-07-01', Finish='2024-07-05', Type='Documentation'),\n",
    "      dict(Task=\"Internship Report\", Start='2024-07-08', Finish='2024-07-12', Type='Documentation'),\n",
    "      dict(Task=\"Internship Report\", Start='2024-07-15', Finish='2024-07-19', Type='Documentation'),\n",
    "\n",
    "      ])\n",
    "\n",
    "\n",
    "fig = px.timeline(df, x_start=\"Start\", x_end=\"Finish\", y=\"Task\", color=\"Type\")\n",
    "fig.update_yaxes(autorange=\"reversed\", showgrid=True, gridwidth=1, gridcolor='white')\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_depth_statistics_v2(depth_path, assembly_file):\n",
    "    \"\"\"\n",
    "    Calcula estatísticas de profundidade para genes com base em um arquivo de profundidade e um arquivo de montagem.\n",
    "\n",
    "    Args:\n",
    "        depth_path (str): O caminho para o arquivo de profundidade.\n",
    "        assembly_file (str): O caminho para o arquivo de montagem.\n",
    "\n",
    "    Returns:\n",
    "        dict: Um dicionário onde as chaves são os nomes dos genes e os valores são tuplas contendo a contagem de nucleotídeos\n",
    "              e a soma de profundidades para aquele gene.\n",
    "    \"\"\"\n",
    "    # Inicializa um dicionário para armazenar a contagem de nucleotídeos e a soma de profundidades para cada gene\n",
    "    gene_depth_statistics = {}\n",
    "\n",
    "    # Lê o arquivo de montagem e armazena os intervalos de exões e calcula os intervalos de genes\n",
    "    exon_intervals = {}\n",
    "    gene_intervals = {}\n",
    "    with open(assembly_file, 'r') as assembly:\n",
    "        for line in assembly:\n",
    "            fields = line.strip().split()\n",
    "            gene = fields[3]\n",
    "            start = int(fields[1])\n",
    "            end = int(fields[2])\n",
    "            if gene not in exon_intervals:\n",
    "                exon_intervals[gene] = []\n",
    "            exon_intervals[gene].append((start, end))\n",
    "            # Atualiza os intervalos de genes\n",
    "            if gene not in gene_intervals:\n",
    "                gene_intervals[gene] = (start, end)\n",
    "            else:\n",
    "                gene_intervals[gene] = (min(start, gene_intervals[gene][0]), max(end, gene_intervals[gene][1]))\n",
    "\n",
    "    # Itera sobre o arquivo de profundidade para calcular as estatísticas\n",
    "    with open(depth_path, 'r') as depth_file:\n",
    "        for line in depth_file:\n",
    "            fields = line.strip().split()\n",
    "            nucleotide_position = int(fields[1])\n",
    "            depth = float(fields[2])\n",
    "            gene_found = False\n",
    "\n",
    "            # Verifica se o nucleotídeo está dentro dos intervalos de exões de algum gene\n",
    "            for gene, intervals in exon_intervals.items():\n",
    "                for start, end in intervals:\n",
    "                    if start <= nucleotide_position <= end:\n",
    "                        # Atualiza as estatísticas para o gene correspondente\n",
    "                        gene_found = True\n",
    "                        if gene not in gene_depth_statistics:\n",
    "                            gene_depth_statistics[gene] = [0, 0]  # Inicializa a contagem de nucleotídeos e a soma de profundidades\n",
    "                        gene_depth_statistics[gene][0] += 1  # Incrementa a contagem de nucleotídeos\n",
    "                        gene_depth_statistics[gene][1] += depth  # Adiciona a profundidade ao total\n",
    "\n",
    "            if not gene_found:\n",
    "                print(f\"Warning: Nucleotide position {nucleotide_position} not within any gene interval.\")\n",
    "\n",
    "    return gene_depth_statistics\n",
    "\n",
    "# Exemplo de uso:\n",
    "depth_path = \"data/depth/1101542.depth\"\n",
    "assembly_file = \"data/regions/genome_exons/UCSC_hg19_exons_modif_canonical_with_difference_chr.bed\"\n",
    "statistics = calculate_depth_statistics_v2(depth_path, assembly_file)\n",
    "print(statistics)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TWIST BED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "awk '{split ($4,a,\",\"); {print $1\"\\t\"$2\"\\t\"$3\"\\t\"a[1]}}' data/regions/genome_exons/hg19_Twist_ILMN_Exome_2.0_Plus_Panel_annotated.BED > data/regions/genome_exons/hg19_Twist_ILMN_Exome_2.0_Plus_Panel_annotated_modif.BED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "awk '{split ($4,a,\",\"); {print $1\"\\t\"$2\"\\t\"$3\"\\t\"a[1]}}' data/regions/genome_exons/hg38_Twist_ILMN_Exome_2.0_Plus_Panel_annotated.BED > data/regions/genome_exons/hg38_Twist_ILMN_Exome_2.0_Plus_Panel_annotated_modif.BED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "awk '\n",
    "{\n",
    "    split($4, a, \",\");\n",
    "    gene = a[1];\n",
    "    if (gene != last_gene) {\n",
    "        count = 1;\n",
    "    } else {\n",
    "        count++;\n",
    "    }\n",
    "    diff = $3 - $2;\n",
    "    last_gene = gene;\n",
    "    print $1 \"\\t\" $2 \"\\t\" $3 \"\\t\" gene \"\\t\" count \"\\t\" diff\n",
    "}' data/regions/genome_exons/hg19_Twist_ILMN_Exome_2.0_Plus_Panel_annotated.BED > data/regions/genome_exons/hg19_Twist_ILMN_Exome_2.0_Plus_Panel_annotated_modif.bed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "awk '\n",
    "{\n",
    "    split($4, a, \",\");\n",
    "    gene = a[1];\n",
    "    if (gene != last_gene) {\n",
    "        count = 1;\n",
    "    } else {\n",
    "        count++;\n",
    "    }\n",
    "    diff = $3 - $2;\n",
    "    chr_num = substr($1, 4);  # Remove os primeiros três caracteres (\"chr\")\n",
    "    last_gene = gene;\n",
    "    print chr_num \"\\t\" $2 \"\\t\" $3 \"\\t\" gene \"\\t\" count \"\\t\" diff\n",
    "}' data/regions/genome_exons/hg19_Twist_ILMN_Exome_2.0_Plus_Panel_annotated.BED > data/regions/genome_exons/hg19_Twist_ILMN_Exome_2.0_Plus_Panel_annotated_modif_nochr.bed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "awk '\n",
    "{\n",
    "    split($4, a, \",\");\n",
    "    gene = a[1];\n",
    "    if (gene != last_gene) {\n",
    "        count = 1;\n",
    "    } else {\n",
    "        count++;\n",
    "    }\n",
    "    diff = $3 - $2;\n",
    "    last_gene = gene;\n",
    "    print $1 \"\\t\" $2 \"\\t\" $3 \"\\t\" gene \"\\t\" count \"\\t\" diff\n",
    "}' data/regions/genome_exons/hg38_Twist_ILMN_Exome_2.0_Plus_Panel_annotated.BED > data/regions/genome_exons/hg38_Twist_ILMN_Exome_2.0_Plus_Panel_annotated_modif.bed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "awk '\n",
    "{\n",
    "    split($4, a, \",\");\n",
    "    gene = a[1];\n",
    "    if (gene != last_gene) {\n",
    "        count = 1;\n",
    "    } else {\n",
    "        count++;\n",
    "    }\n",
    "    diff = $3 - $2;\n",
    "    chr_num = substr($1, 4);  # Remove os primeiros três caracteres (\"chr\")\n",
    "    last_gene = gene;\n",
    "    print chr_num \"\\t\" $2 \"\\t\" $3 \"\\t\" gene \"\\t\" count \"\\t\" diff\n",
    "}' data/regions/genome_exons/hg38_Twist_ILMN_Exome_2.0_Plus_Panel_annotated.BED > data/regions/genome_exons/hg38_Twist_ILMN_Exome_2.0_Plus_Panel_annotated_modif_nochr.bed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C:\\Users\\ptpedfilven\\Downloads\\Painel Epilepsia.bed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "universal_bed = pd.read_csv('/Users/ptpedfilven/Downloads/Painel Doença de Alzheimer.bed', sep='\\t', header=None)\n",
    "df = pd.DataFrame(universal_bed)\n",
    "df.head()\n",
    "sorted(df[3].unique().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install --trusted-host pypi.org --trusted-host files.pythonhosted.org selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "\n",
    "\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "driver.get(\"http://selenium.dev\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install --trusted-host pypi.org --trusted-host files.pythonhosted.org s3fs\n",
    "%pip install --trusted-host pypi.org --trusted-host files.pythonhosted.org st-files-connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "from st_files_connection import FilesConnection\n",
    "import s3fs as s3\n",
    "\n",
    "conn = st.connection('s3', type=FilesConnection)\n",
    "df2 = conn.read(\"unilabs/bam_bed_map.csv\", input_format=\"csv\", ttl=600)\n",
    "st.dataframe(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "from st_files_connection import FilesConnection\n",
    "\n",
    "def list_cram_files(directory='unilabs/'):\n",
    "    # Conectar ao bucket S3\n",
    "    conn = st.connection('s3', type=FilesConnection)\n",
    "    \n",
    "    # Função recursiva para listar ficheiros .cram em subdiretórios\n",
    "    def list_files_recursively(current_directory):\n",
    "        files = conn.fs.ls(current_directory)\n",
    "        cram_files = []\n",
    "        for file in files:\n",
    "            if file.endswith('.cram'):\n",
    "                cram_files.append(file)\n",
    "            elif file.endswith('/'):  # É um diretório, explorar recursivamente\n",
    "                cram_files.extend(list_files_recursively(file))\n",
    "        return cram_files\n",
    "\n",
    "    # Chamar a função recursiva começando no diretório inicial\n",
    "    all_cram_files = list_files_recursively(directory)\n",
    "    \n",
    "    return all_cram_files\n",
    "\n",
    "# Exemplo de chamada da função\n",
    "cram_files = list_cram_files('unilabs/')\n",
    "print(cram_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "# Comando AWK\n",
    "awk_command = (\n",
    "    \"awk -v gene_filter=A1BG -v exon_filter=1,2 \"\n",
    "    \"'BEGIN {split(exon_filter, arr, \\\",\\\")}; \"\n",
    "    \"($4 == gene_filter || gene_filter == \\\"\\\") && (\\\"\\\" in arr || $5 == arr[1]) {\"\n",
    "    \"sub(/^chr/, \\\"\\\", $1); print}' \"\n",
    "    \"data/regions/genome_exons/hg19_Twist_ILMN_Exome_2.0_Plus_Panel_annotated_modif_nochr.BED\"\n",
    ")\n",
    "\n",
    "# Comando completo\n",
    "full_command = f\"{awk_command} | samtools depth -b - None > data/depth\"\n",
    "\n",
    "try:\n",
    "    # Executar o comando\n",
    "    result = subprocess.run(full_command, shell=True, check=True, text=True, capture_output=True)\n",
    "    print(result.stdout)\n",
    "except subprocess.CalledProcessError as e:\n",
    "    print(f\"Error occurred: {e.stderr}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import boto3\n",
    "import subprocess\n",
    "\n",
    "def cram():\n",
    "    # Obtém a chave do arquivo CRAM a partir do estado da sessão\n",
    "    cram_key = \"1039352/Mapper/v4.0.3-hg38_42d7dbc/1039352.cram\"\n",
    "\n",
    "    # Cria um stream BytesIO para armazenar os dados do arquivo CRAM baixado\n",
    "    cram_stream = io.BytesIO()\n",
    "\n",
    "    # Configura credenciais específicas para o boto3\n",
    "    session = boto3.Session(\n",
    "        aws_access_key_id=\"AKIAYS2NUI5DIOJAT5KZ\",\n",
    "        aws_secret_access_key=\"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\",\n",
    "        region_name=\"eu-north-1\"  # Substitua pela região do seu bucket S3\n",
    "    )\n",
    "    \n",
    "    # Cria o cliente S3 usando a sessão com credenciais específicas\n",
    "    s3_client = session.client('s3')\n",
    "\n",
    "    # Baixa o arquivo CRAM do S3 para o stream BytesIO\n",
    "    s3_client.download_fileobj('unilabs', cram_key, cram_stream)\n",
    "\n",
    "    # Certifica-se de voltar ao início do stream antes de usá-lo\n",
    "    cram_stream.seek(0)\n",
    "    \n",
    "    return cram_stream\n",
    "\n",
    "gene_selection = 'A1BG'\n",
    "exon_selection = [1, 2]\n",
    "bed_path = 'data/regions/genome_exons/hg19_Twist_ILMN_Exome_2.0_Plus_Panel_annotated_modif.BED'\n",
    "cram_stream = cram()\n",
    "gene_filter = gene_selection if gene_selection else ''\n",
    "print(gene_filter)\n",
    "exon_filter = ','.join(map(str, exon_selection)) if exon_selection else ''\n",
    "print(exon_filter)\n",
    "\n",
    "awk_command = f\"awk -v gene_filter={gene_filter} -v exon_filter={exon_filter} '{{split(exon_filter, arr, \\\",\\\"); if (($4 == gene_filter || gene_filter == \\\"\\\") && (\\\"\\\" in arr || $5 == arr[1])) {{sub(/^chr/, \\\"\\\", $1); print}}}}' {bed_path}\"\n",
    "\n",
    "# Note: Subprocess call should include proper path handling for the depth_path\n",
    "depth_path = 'output_depth.txt'\n",
    "cram_path = '/tmp/1039352.cram'  # Salve o stream em um arquivo temporário\n",
    "with open(cram_path, 'wb') as f:\n",
    "    f.write(cram_stream.getvalue())\n",
    "\n",
    "samtools_command = f\"samtools depth -b - {cram_path} > {depth_path}\"\n",
    "\n",
    "subprocess.run(f\"{awk_command} | {samtools_command}\", shell=True, check=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bioinformatics",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
